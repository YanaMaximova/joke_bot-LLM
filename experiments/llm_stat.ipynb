{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-19T18:42:35.450188Z",
     "iopub.status.busy": "2024-03-19T18:42:35.449674Z",
     "iopub.status.idle": "2024-03-19T18:42:35.465901Z",
     "shell.execute_reply": "2024-03-19T18:42:35.464812Z",
     "shell.execute_reply.started": "2024-03-19T18:42:35.450150Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/russian-jokes/jokes.csv\n",
      "/kaggle/input/vk-anekdots/anekdots_result.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import pickle \n",
    "from itertools import chain\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "from typing import List, Dict, Optional, Iterable, Tuple\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:40:05.630673Z",
     "iopub.status.busy": "2024-03-19T18:40:05.629561Z",
     "iopub.status.idle": "2024-03-19T18:40:05.654618Z",
     "shell.execute_reply": "2024-03-19T18:40:05.653334Z",
     "shell.execute_reply.started": "2024-03-19T18:40:05.630621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self,\n",
    "                 token_pattern: str = '\\w+|[\\!\\?\\,\\.\\-\\:]',\n",
    "                 eos_token: str = '<EOS>',\n",
    "                 pad_token: str = '<PAD>',\n",
    "                 unk_token: str = '<UNK>'):\n",
    "        self.token_pattern = token_pattern\n",
    "        self.eos_token = eos_token\n",
    "        self.pad_token = pad_token\n",
    "        self.unk_token = unk_token\n",
    "        \n",
    "        self.special_tokens = [self.eos_token, self.pad_token, self.unk_token]\n",
    "        self.vocab = None\n",
    "        self.inverse_vocab = None\n",
    "    \n",
    "    def text_preprocess(self, input_text: str) -> str:\n",
    "        \"\"\" Предобрабатываем один текст \"\"\"\n",
    "        input_text = input_text.lower()\n",
    "        input_text = re.sub(r'\\s+', ' ', input_text) \n",
    "        input_text = input_text.strip()\n",
    "        return input_text\n",
    "    \n",
    "    def build_vocab(self, corpus: List[str]) -> None:\n",
    "        assert len(corpus)\n",
    "        all_tokens = set()\n",
    "        for text in corpus:\n",
    "            all_tokens |= set(self._tokenize(text, append_eos_token=False))\n",
    "        self.vocab = {elem: ind for ind, elem in enumerate(all_tokens)}\n",
    "        special_tokens = [self.eos_token, self.unk_token, self.pad_token]\n",
    "        for token in special_tokens:\n",
    "            self.vocab[token] = len(self.vocab)\n",
    "        self.inverse_vocab = {ind: elem for elem, ind in self.vocab.items()}\n",
    "        return self\n",
    "        \n",
    "    def _tokenize(self, text: str, append_eos_token: bool = True) -> List[str]:\n",
    "        text = self.text_preprocess(text)\n",
    "        tokens = re.findall(self.token_pattern, text)\n",
    "        if append_eos_token:\n",
    "            tokens.append(self.eos_token)\n",
    "        return tokens\n",
    "    \n",
    "    def encode(self, text: str, append_eos_token: bool = True) -> List[str]:\n",
    "        \"\"\" Токенизируем текст \"\"\"\n",
    "        tokens = self._tokenize(text, append_eos_token)\n",
    "        ids = [self.vocab.get(token, self.vocab[self.unk_token]) for token in tokens]\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, input_ids: Iterable[int], remove_special_tokens: bool = False) -> str:\n",
    "        assert len(input_ids)\n",
    "        assert max(input_ids) < len(self.vocab) and min(input_ids) >= 0\n",
    "        tokens = []\n",
    "        for ind in input_ids:\n",
    "            token = self.inverse_vocab[ind]\n",
    "            if remove_special_tokens and token in self.special_tokens:\n",
    "                continue\n",
    "            tokens.append(token)\n",
    "        text = ' '.join( tokens )\n",
    "        return text\n",
    "    \n",
    "    def save(self, path: str) -> bool:\n",
    "        data = {\n",
    "            'token_pattern': self.token_pattern,\n",
    "            'eos_token': self.eos_token,\n",
    "            'pad_token': self.pad_token,\n",
    "            'unk_token': self.unk_token,\n",
    "            'special_tokens': self.special_tokens,\n",
    "            'vocab': self.vocab,\n",
    "            'inverse_vocab': self.inverse_vocab,\n",
    "        }\n",
    "        \n",
    "        with open(path, 'wb') as fout:\n",
    "            pickle.dump(data, fout)\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    def load(self, path: str) -> bool:\n",
    "        with open(path, 'rb') as fin:\n",
    "            data = pickle.load(fin)\n",
    "            \n",
    "        self.token_pattern = data['token_pattern']\n",
    "        self.eos_token = data['eos_token']\n",
    "        self.pad_token = data['pad_token']\n",
    "        self.unk_token = data['unk_token']\n",
    "        self.special_tokens = data['special_tokens']\n",
    "        self.vocab = data['vocab']\n",
    "        self.inverse_vocab = data['inverse_vocab']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:40:05.656505Z",
     "iopub.status.busy": "2024-03-19T18:40:05.656111Z",
     "iopub.status.idle": "2024-03-19T18:40:05.675672Z",
     "shell.execute_reply": "2024-03-19T18:40:05.674098Z",
     "shell.execute_reply.started": "2024-03-19T18:40:05.656475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GenerationConfig:\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Тут можно задать любые параметры и их значения по умолчанию\n",
    "        Значения для стратегии декодирования decoding_strategy: ['max', 'top-p']\n",
    "        \"\"\"\n",
    "        self.temperature = kwargs.pop(\"temperature\", 1.0)\n",
    "        self.max_tokens = kwargs.pop(\"max_tokens\", 32)\n",
    "        self.sample_top_p = kwargs.pop(\"sample_top_p\", 0.9)\n",
    "        self.decoding_strategy = kwargs.pop(\"decoding_strategy\", 'max')\n",
    "        self.remove_special_tokens = kwargs.pop(\"remove_special_tokens\", False)\n",
    "        self.validate()\n",
    "        \n",
    "    def validate(self):\n",
    "        \"\"\" Здесь можно валидировать параметры \"\"\"\n",
    "        if not (1.0 > self.sample_top_p > 0):\n",
    "            raise ValueError('sample_top_p')\n",
    "        if self.decoding_strategy not in ['max', 'top-p']:\n",
    "            raise ValueError('decoding_strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:40:05.742853Z",
     "iopub.status.busy": "2024-03-19T18:40:05.741886Z",
     "iopub.status.idle": "2024-03-19T18:40:05.777340Z",
     "shell.execute_reply": "2024-03-19T18:40:05.776073Z",
     "shell.execute_reply.started": "2024-03-19T18:40:05.742815Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class StatLM:\n",
    "    def __init__(self, \n",
    "                 tokenizer: Tokenizer,\n",
    "                 context_size: int = 2,\n",
    "                 alpha: float = 0.1\n",
    "                ):\n",
    "        \n",
    "        assert context_size >= 2\n",
    "        \n",
    "        self.context_size = context_size\n",
    "        self.tokenizer = tokenizer\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        self.n_gramms_stat = defaultdict(int)\n",
    "        self.nx_gramms_stat = defaultdict(int)\n",
    "        \n",
    "    def get_token_by_ind(ind: int) -> str:\n",
    "        return self.tokenizer.vocab.get(ind)\n",
    "    \n",
    "    def get_ind_by_token(token: str) -> int:\n",
    "        return self.tokenizer.inverse_vocab.get(token, self.tokenizer.inverse_vocab[self.unk_token])\n",
    "        \n",
    "    def train(self, train_texts: List[str]):\n",
    "        for sentence in tqdm(train_texts, desc='train lines'):\n",
    "            sentence_ind = self.tokenizer.encode(sentence)\n",
    "            for i in range(len(sentence_ind) - self.context_size):\n",
    "                \n",
    "                seq = tuple(sentence_ind[i: i + self.context_size - 1])\n",
    "                self.n_gramms_stat[seq] += 1\n",
    "                \n",
    "                seq_x = tuple(sentence_ind[i: i + self.context_size])\n",
    "                self.nx_gramms_stat[seq_x] += 1\n",
    "                \n",
    "            seq = tuple(sentence_ind[len(sentence_ind) - self.context_size:])\n",
    "            self.n_gramms_stat[seq] += 1\n",
    "            \n",
    "    def sample_token(self, \n",
    "                     token_distribution: np.ndarray,\n",
    "                     generation_config: GenerationConfig) -> int:\n",
    "        if generation_config.decoding_strategy == 'max':\n",
    "            return token_distribution.argmax()\n",
    "        elif generation_config.decoding_strategy == 'top-p':\n",
    "            token_distribution = sorted(list(zip(token_distribution, np.arange(len(token_distribution)))),\n",
    "                                        reverse=True)\n",
    "            total_proba = 0.0\n",
    "            tokens_to_sample = []\n",
    "            tokens_probas = []\n",
    "            for token_proba, ind in token_distribution:\n",
    "                tokens_to_sample.append(ind)\n",
    "                tokens_probas.append(token_proba)\n",
    "                total_proba += token_proba\n",
    "                if total_proba >= generation_config.sample_top_p:\n",
    "                    break\n",
    "\n",
    "            tokens_probas = np.array(tokens_probas) / generation_config.temperature\n",
    "            tokens_probas = tokens_probas / tokens_probas.sum()\n",
    "            return np.random.choice(tokens_to_sample, p=tokens_probas)\n",
    "        else:\n",
    "            raise ValueError(f'Unknown decoding strategy: {generation_config.decoding_strategy}')\n",
    "            \n",
    "    def save_stat(self, path: str) -> bool:\n",
    "        stat = {\n",
    "            'n_gramms_stat': self.n_gramms_stat,\n",
    "            'nx_gramms_stat': self.nx_gramms_stat,\n",
    "            'context_size': self.context_size,\n",
    "            'alpha': self.alpha\n",
    "        }\n",
    "        with open(path, 'wb') as fout:\n",
    "            pickle.dump(stat, fout)\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def load_stat(self, path: str) -> bool:\n",
    "        with open(path, 'rb') as fin:\n",
    "            stat = pickle.load(fin)\n",
    "            \n",
    "        self.n_gramms_stat = stat['n_gramms_stat']\n",
    "        self.nx_gramms_stat = stat['nx_gramms_stat']\n",
    "        self.context_size = stat['context_size']\n",
    "        self.alpha = stat['alpha']\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    def get_stat(self) -> Dict[str, Dict]:\n",
    "        \n",
    "        n_token_stat, nx_token_stat = {}, {}\n",
    "        for token_inds, count in self.n_gramms_stat.items():\n",
    "            n_token_stat[self.tokenizer.decode(token_inds)] = count\n",
    "        \n",
    "        for token_inds, count in self.nx_gramms_stat.items():\n",
    "            nx_token_stat[self.tokenizer.decode(token_inds)] = count\n",
    "        \n",
    "        return {\n",
    "            'n gramms stat': self.n_gramms_stat,\n",
    "            'n+1 gramms stat': self.nx_gramms_stat,\n",
    "            'n tokens stat': n_token_stat,\n",
    "            'n+1 tokens stat': nx_token_stat,\n",
    "        }\n",
    "    \n",
    "    def _get_next_token(self, \n",
    "                        tokens: List[int],\n",
    "                        generation_config: GenerationConfig) -> (int, str):\n",
    "        denominator = self.n_gramms_stat.get(tuple(tokens), 0) + self.alpha * len(self.tokenizer.vocab)\n",
    "        numerators = []\n",
    "        for ind in self.tokenizer.inverse_vocab:\n",
    "            numerators.append(self.nx_gramms_stat.get(tuple(tokens + [ind]), 0) + self.alpha)\n",
    "        \n",
    "        token_distribution = np.array(numerators) / denominator\n",
    "        max_proba_ind = self.sample_token(token_distribution, generation_config)\n",
    "        \n",
    "        next_token = self.tokenizer.inverse_vocab[max_proba_ind]\n",
    "        \n",
    "        return max_proba_ind, next_token\n",
    "            \n",
    "    def generate_token(self, \n",
    "                       text: str, \n",
    "                       generation_config: GenerationConfig\n",
    "                      ) -> Dict:\n",
    "        tokens = self.tokenizer.encode(text, append_eos_token=False)\n",
    "        tokens = tokens[-self.context_size + 1:]\n",
    "        \n",
    "        max_proba_ind, next_token = self._get_next_token(tokens, generation_config)\n",
    "        \n",
    "        return {\n",
    "            'next_token': next_token,\n",
    "            'next_token_num': max_proba_ind,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def generate_text(self, text: str, \n",
    "                      generation_config: GenerationConfig\n",
    "                     ) -> Dict:\n",
    "        \n",
    "        all_tokens = self.tokenizer.encode(text, append_eos_token=False)\n",
    "        tokens = all_tokens[-self.context_size + 1:]\n",
    "        \n",
    "        next_token = None\n",
    "        while next_token != self.tokenizer.eos_token and len(all_tokens) < generation_config.max_tokens:\n",
    "            max_proba_ind, next_token = self._get_next_token(tokens, generation_config)\n",
    "            all_tokens.append(max_proba_ind)\n",
    "            tokens = all_tokens[-self.context_size + 1:]\n",
    "        \n",
    "        new_text = self.tokenizer.decode(all_tokens, generation_config.remove_special_tokens)\n",
    "        \n",
    "        finish_reason = 'max tokens'\n",
    "        if all_tokens[-1] == self.tokenizer.vocab[self.tokenizer.eos_token]:\n",
    "            finish_reason = 'end of text'\n",
    "        \n",
    "        return {\n",
    "            'all_tokens': all_tokens,\n",
    "            'total_text': new_text,\n",
    "            'finish_reason': finish_reason\n",
    "        }\n",
    "    \n",
    "    def generate(self, text: str, generation_config: Dict) -> str:\n",
    "        return self.generate_text(text, generation_config)['total_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:40:05.780134Z",
     "iopub.status.busy": "2024-03-19T18:40:05.779794Z",
     "iopub.status.idle": "2024-03-19T18:40:06.787433Z",
     "shell.execute_reply": "2024-03-19T18:40:06.785908Z",
     "shell.execute_reply.started": "2024-03-19T18:40:05.780108Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130204"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = pd.read_csv('../input/russian-jokes/jokes.csv')['text']\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:40:06.789566Z",
     "iopub.status.busy": "2024-03-19T18:40:06.789110Z",
     "iopub.status.idle": "2024-03-19T18:40:09.643930Z",
     "shell.execute_reply": "2024-03-19T18:40:09.642810Z",
     "shell.execute_reply.started": "2024-03-19T18:40:06.789529Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233683"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added_texts = pd.read_csv('../input/vk-anekdots/anekdots_result.csv')['text']\n",
    "len(added_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:44:36.969045Z",
     "iopub.status.busy": "2024-03-19T18:44:36.968549Z",
     "iopub.status.idle": "2024-03-19T18:44:37.026499Z",
     "shell.execute_reply": "2024-03-19T18:44:37.025320Z",
     "shell.execute_reply.started": "2024-03-19T18:44:36.969012Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>На суде в Стамбуле обвиняемый сказал:\\r\\n- На...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- Вы продолжаете утверждать, что обвиняемый н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>На суде.\\r\\n- Итак, когда дело дошло до столкн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Старую леди сбил автомобиль. На суде ее спраши...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Судья говорит:\\r\\n- Согласно вашей жалобе, об...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363882</th>\n",
       "      <td>Это абсолютно реальная история, которую расска...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363883</th>\n",
       "      <td>В один престижный бутик заходит блондинистая к...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363884</th>\n",
       "      <td>Маршрутка. Заходит бабулька божий одуванчик. П...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363885</th>\n",
       "      <td>И чего только пьяному человеку в голову не при...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363886</th>\n",
       "      <td>Мой друг входит в топ-менеджмент одного банка....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363887 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "0       На суде в Стамбуле обвиняемый сказал:\\r\\n- На...\n",
       "1       - Вы продолжаете утверждать, что обвиняемый н...\n",
       "2       На суде.\\r\\n- Итак, когда дело дошло до столкн...\n",
       "3       Старую леди сбил автомобиль. На суде ее спраши...\n",
       "4       Судья говорит:\\r\\n- Согласно вашей жалобе, об...\n",
       "...                                                   ...\n",
       "363882  Это абсолютно реальная история, которую расска...\n",
       "363883  В один престижный бутик заходит блондинистая к...\n",
       "363884  Маршрутка. Заходит бабулька божий одуванчик. П...\n",
       "363885  И чего только пьяному человеку в голову не при...\n",
       "363886  Мой друг входит в топ-менеджмент одного банка....\n",
       "\n",
       "[363887 rows x 1 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([texts, added_texts], axis=0).reset_index().drop('index', axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:44:39.274638Z",
     "iopub.status.busy": "2024-03-19T18:44:39.273938Z",
     "iopub.status.idle": "2024-03-19T18:44:39.580005Z",
     "shell.execute_reply": "2024-03-19T18:44:39.578681Z",
     "shell.execute_reply.started": "2024-03-19T18:44:39.274601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "str_lenghts = data['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:44:40.499159Z",
     "iopub.status.busy": "2024-03-19T18:44:40.498763Z",
     "iopub.status.idle": "2024-03-19T18:44:47.130359Z",
     "shell.execute_reply": "2024-03-19T18:44:47.129371Z",
     "shell.execute_reply.started": "2024-03-19T18:44:40.499131Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.set_xlim(0, 1000)\n",
    "ax.set_xlabel('text_length')\n",
    "sns.histplot(str_lenghts, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:44:49.662880Z",
     "iopub.status.busy": "2024-03-19T18:44:49.662390Z",
     "iopub.status.idle": "2024-03-19T18:44:49.677788Z",
     "shell.execute_reply": "2024-03-19T18:44:49.676751Z",
     "shell.execute_reply.started": "2024-03-19T18:44:49.662848Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = str_lenghts.quantile(q=0.9)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:44:51.622205Z",
     "iopub.status.busy": "2024-03-19T18:44:51.621793Z",
     "iopub.status.idle": "2024-03-19T18:44:51.628340Z",
     "shell.execute_reply": "2024-03-19T18:44:51.627225Z",
     "shell.execute_reply.started": "2024-03-19T18:44:51.622175Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "small_indexes = (str_lenghts <= q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:44:55.899071Z",
     "iopub.status.busy": "2024-03-19T18:44:55.898535Z",
     "iopub.status.idle": "2024-03-19T18:44:55.949604Z",
     "shell.execute_reply": "2024-03-19T18:44:55.947950Z",
     "shell.execute_reply.started": "2024-03-19T18:44:55.899034Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327580"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[small_indexes]\n",
    "data = data.reset_index(drop=True)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:44:57.552320Z",
     "iopub.status.busy": "2024-03-19T18:44:57.551735Z",
     "iopub.status.idle": "2024-03-19T18:45:05.933535Z",
     "shell.execute_reply": "2024-03-19T18:45:05.932356Z",
     "shell.execute_reply.started": "2024-03-19T18:44:57.552277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "unique_ind = data['text'].apply(lambda x: re.sub(r'[^а-яА-Я0-9]', '', x.lower())).drop_duplicates().index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:45:07.201721Z",
     "iopub.status.busy": "2024-03-19T18:45:07.200481Z",
     "iopub.status.idle": "2024-03-19T18:45:07.246401Z",
     "shell.execute_reply": "2024-03-19T18:45:07.245069Z",
     "shell.execute_reply.started": "2024-03-19T18:45:07.201685Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>На суде в Стамбуле обвиняемый сказал:\\r\\n- На...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- Вы продолжаете утверждать, что обвиняемый н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>На суде.\\r\\n- Итак, когда дело дошло до столкн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Старую леди сбил автомобиль. На суде ее спраши...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Судья говорит:\\r\\n- Согласно вашей жалобе, об...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321525</th>\n",
       "      <td>Позвонил друг, поделился восторгом.\\nОн себе с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321526</th>\n",
       "      <td>Реальное объявление в мастерской по ремонту об...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321527</th>\n",
       "      <td>Не так давно предлагаю ребёнку отгадать извест...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321528</th>\n",
       "      <td>Лежим с женой в спальне, смотрим романтическую...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321529</th>\n",
       "      <td>Маршрутка. Заходит бабулька божий одуванчик. П...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321530 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "0       На суде в Стамбуле обвиняемый сказал:\\r\\n- На...\n",
       "1       - Вы продолжаете утверждать, что обвиняемый н...\n",
       "2       На суде.\\r\\n- Итак, когда дело дошло до столкн...\n",
       "3       Старую леди сбил автомобиль. На суде ее спраши...\n",
       "4       Судья говорит:\\r\\n- Согласно вашей жалобе, об...\n",
       "...                                                   ...\n",
       "321525  Позвонил друг, поделился восторгом.\\nОн себе с...\n",
       "321526  Реальное объявление в мастерской по ремонту об...\n",
       "321527  Не так давно предлагаю ребёнку отгадать извест...\n",
       "321528  Лежим с женой в спальне, смотрим романтическую...\n",
       "321529  Маршрутка. Заходит бабулька божий одуванчик. П...\n",
       "\n",
       "[321530 rows x 1 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.iloc[unique_ind]\n",
    "data = data.reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:45:20.566411Z",
     "iopub.status.busy": "2024-03-19T18:45:20.565932Z",
     "iopub.status.idle": "2024-03-19T18:45:26.303579Z",
     "shell.execute_reply": "2024-03-19T18:45:26.302087Z",
     "shell.execute_reply.started": "2024-03-19T18:45:20.566378Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x))\n",
    "data['text'] = data['text'].apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:45:51.121290Z",
     "iopub.status.busy": "2024-03-19T18:45:51.120854Z",
     "iopub.status.idle": "2024-03-19T18:45:53.593601Z",
     "shell.execute_reply": "2024-03-19T18:45:53.592622Z",
     "shell.execute_reply.started": "2024-03-19T18:45:51.121240Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: re.sub(r'[^а-яА-Я0-9 -]', '', x.replace(',', ' ').lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:47:07.387879Z",
     "iopub.status.busy": "2024-03-19T18:47:07.387427Z",
     "iopub.status.idle": "2024-03-19T18:47:07.398466Z",
     "shell.execute_reply": "2024-03-19T18:47:07.396771Z",
     "shell.execute_reply.started": "2024-03-19T18:47:07.387848Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    на суде в стамбуле обвиняемыи сказал на свои ж...\n",
       "1    вы продолжаете утверждать что обвиняемыи назва...\n",
       "2    на суде итак когда дело дошло до столкновения ...\n",
       "3    старую леди сбил автомобиль на суде ее спрашив...\n",
       "4    судья говорит согласно вашеи жалобе обвиняемыи...\n",
       "5    на судебном заседании гражданка дроздова мы ра...\n",
       "6    драка происходила так однои рукои я схватил ег...\n",
       "7    судья свидетель вы должны говорить правду одну...\n",
       "8    судья подсудимому ну ну перестаньте волноватьс...\n",
       "9    судья спрашивает четырех индеи цев убежавших и...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:47:09.886427Z",
     "iopub.status.busy": "2024-03-19T18:47:09.885060Z",
     "iopub.status.idle": "2024-03-19T18:47:09.891953Z",
     "shell.execute_reply": "2024-03-19T18:47:09.890623Z",
     "shell.execute_reply.started": "2024-03-19T18:47:09.886387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(temperature = 1.0, max_tokens = 16,\n",
    "                                     sample_top_p = 0.1, decoding_strategy = 'top-p',\n",
    "                                     remove_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:47:55.237810Z",
     "iopub.status.busy": "2024-03-19T18:47:55.237382Z",
     "iopub.status.idle": "2024-03-19T18:48:09.433777Z",
     "shell.execute_reply": "2024-03-19T18:48:09.432213Z",
     "shell.execute_reply.started": "2024-03-19T18:47:55.237779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer().build_vocab(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T19:03:36.323568Z",
     "iopub.status.busy": "2024-03-19T19:03:36.323105Z",
     "iopub.status.idle": "2024-03-19T19:04:17.242066Z",
     "shell.execute_reply": "2024-03-19T19:04:17.240769Z",
     "shell.execute_reply.started": "2024-03-19T19:03:36.323540Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ba1c62f09648559bd08019d6c0dec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train lines:   0%|          | 0/321530 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stat_lm = StatLM(tokenizer, context_size=3, alpha=0.001)\n",
    "stat_lm.train(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:58:11.668996Z",
     "iopub.status.busy": "2024-03-19T18:58:11.668510Z",
     "iopub.status.idle": "2024-03-19T18:58:11.675368Z",
     "shell.execute_reply": "2024-03-19T18:58:11.674240Z",
     "shell.execute_reply.started": "2024-03-19T18:58:11.668957Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    'встретились как-то русский и американец',\n",
    "    'сидит штирлиц в засаде',\n",
    "    'приехала как-то теща в гости',\n",
    "    'говорит чебурашка гене',\n",
    "    'что общего между евреем и'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:58:17.555417Z",
     "iopub.status.busy": "2024-03-19T18:58:17.554919Z",
     "iopub.status.idle": "2024-03-19T18:58:48.381720Z",
     "shell.execute_reply": "2024-03-19T18:58:48.379729Z",
     "shell.execute_reply.started": "2024-03-19T18:58:17.555383Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q0: встретились как то русский и американец попали в ад а черти то чем я могу\n",
      "q1: сидит штирлиц в засаде на лыжне типун протеряешь пнешь вовочкинои шлифуем продвинутых потрохами заструился пргер изучающая\n",
      "q2: приехала как то теща в гости к своему другу в гости к своему другу в\n",
      "q3: говорит чебурашка гене ген а ген а ген а ген а ген а ген а ген\n",
      "q4: что общего между евреем и неглупым человеком а этот лексус уже был помятый и кот это\n"
     ]
    }
   ],
   "source": [
    "for i, test in enumerate(test_data):\n",
    "    ans = stat_lm.generate(test, generation_config)\n",
    "    print(f'q{i}: {ans}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:58:53.908405Z",
     "iopub.status.busy": "2024-03-19T18:58:53.907895Z",
     "iopub.status.idle": "2024-03-19T18:58:53.916330Z",
     "shell.execute_reply": "2024-03-19T18:58:53.914146Z",
     "shell.execute_reply.started": "2024-03-19T18:58:53.908370Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(temperature = 0.1, max_tokens = 16,\n",
    "                                     sample_top_p = 0.1, decoding_strategy = 'top-p',\n",
    "                                     remove_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:59:01.158740Z",
     "iopub.status.busy": "2024-03-19T18:59:01.158219Z",
     "iopub.status.idle": "2024-03-19T18:59:32.631834Z",
     "shell.execute_reply": "2024-03-19T18:59:32.630413Z",
     "shell.execute_reply.started": "2024-03-19T18:59:01.158706Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q0: встретились как то русский и американец американец спокойствие регэкспов полста вилли мыв посодють прибрана больны\n",
      "q1: сидит штирлиц в засаде сидел глобусы обеспеченнои многоэтажка кланая сестрнки выугали радикальное правообладателя вступаешь медным шестеренка\n",
      "q2: приехала как то теща в гости к другу и вместо баллончика тютелька природноочаговое возводим форматироваться\n",
      "q3: говорит чебурашка гене выныривая секретнаая миля тождественныи виникають приятнве напасусь душевными прокаченныи гликозид проешь пашне применяться\n",
      "q4: что общего между евреем и засосет учинил рекордсменке слабовато разрываем куто ладанка стаости четвэрг лечебном выделишь\n"
     ]
    }
   ],
   "source": [
    "for i, test in enumerate(test_data):\n",
    "    ans = stat_lm.generate(test, generation_config)\n",
    "    print(f'q{i}: {ans}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:59:40.109105Z",
     "iopub.status.busy": "2024-03-19T18:59:40.108656Z",
     "iopub.status.idle": "2024-03-19T18:59:40.115719Z",
     "shell.execute_reply": "2024-03-19T18:59:40.114133Z",
     "shell.execute_reply.started": "2024-03-19T18:59:40.109075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(temperature = 0.1, max_tokens = 16,\n",
    "                                     sample_top_p = 0.05, decoding_strategy = 'top-p',\n",
    "                                     remove_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:59:42.394606Z",
     "iopub.status.busy": "2024-03-19T18:59:42.393107Z",
     "iopub.status.idle": "2024-03-19T19:00:13.224437Z",
     "shell.execute_reply": "2024-03-19T19:00:13.223107Z",
     "shell.execute_reply.started": "2024-03-19T18:59:42.394562Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q0: встретились как то русский и американец попали в яму волк лиса мрачнеет кешью глобального индеец\n",
      "q1: сидит штирлиц в засаде на вовочкиным гороскопы благодушно блузке выкройки приспичело волейбол катящийся безвыходности пристойный эстонская\n",
      "q2: приехала как то теща в гости к своему другу вдруг семилетнего детныша охраняемый арнольдович даю\n",
      "q3: говорит чебурашка гене вова послов прохлопала непреклоныи актриса посочувствуют уверяла смэтана компьютерном наполняю разрывающий элитная елдастиш\n",
      "q4: что общего между евреем и армянином впасть венгерском шпилит мерзлота оккупации товарищампострадавшего 92 нокаутом потделок моряки\n"
     ]
    }
   ],
   "source": [
    "for i, test in enumerate(test_data):\n",
    "    ans = stat_lm.generate(test, generation_config)\n",
    "    print(f'q{i}: {ans}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T19:00:25.862086Z",
     "iopub.status.busy": "2024-03-19T19:00:25.861637Z",
     "iopub.status.idle": "2024-03-19T19:00:25.869615Z",
     "shell.execute_reply": "2024-03-19T19:00:25.867869Z",
     "shell.execute_reply.started": "2024-03-19T19:00:25.862053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(temperature = 0.1, max_tokens = 16,\n",
    "                                     sample_top_p = 0.01, decoding_strategy = 'top-p',\n",
    "                                     remove_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T19:00:27.404528Z",
     "iopub.status.busy": "2024-03-19T19:00:27.404064Z",
     "iopub.status.idle": "2024-03-19T19:00:56.964366Z",
     "shell.execute_reply": "2024-03-19T19:00:56.963227Z",
     "shell.execute_reply.started": "2024-03-19T19:00:27.404496Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q0: встретились как то русский и американец попали в ад а черти то бедные бешеные привязанным\n",
      "q1: сидит штирлиц в засаде на лыжне олимп глубинная шабл сказавший молотком4 допиздишься загоню изврашенец благодушно кирпич\n",
      "q2: приехала как то теща в гости к своему другу в гости к своему другу в\n",
      "q3: говорит чебурашка гене ген а ген а ген а ген а ген а ген а ген\n",
      "q4: что общего между евреем и проживающем голосит неприятности элвису фурия ухмылялось кодовым неимущим подслушанныи ангелочки монсерат\n"
     ]
    }
   ],
   "source": [
    "for i, test in enumerate(test_data):\n",
    "    ans = stat_lm.generate(test, generation_config)\n",
    "    print(f'q{i}: {ans}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T19:01:06.205064Z",
     "iopub.status.busy": "2024-03-19T19:01:06.204648Z",
     "iopub.status.idle": "2024-03-19T19:01:06.211021Z",
     "shell.execute_reply": "2024-03-19T19:01:06.209938Z",
     "shell.execute_reply.started": "2024-03-19T19:01:06.205033Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(temperature = 1, max_tokens = 16,\n",
    "                                     sample_top_p = 0.01, decoding_strategy = 'top-p',\n",
    "                                     remove_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T19:01:07.593018Z",
     "iopub.status.busy": "2024-03-19T19:01:07.592582Z",
     "iopub.status.idle": "2024-03-19T19:01:38.411597Z",
     "shell.execute_reply": "2024-03-19T19:01:38.410178Z",
     "shell.execute_reply.started": "2024-03-19T19:01:07.592987Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q0: встретились как то русский и американец попали в ад а черти в котел ее а\n",
      "q1: сидит штирлиц в засаде на углу улицы стоит нищий с хуические хиба долговременное разошлась табачному пилять\n",
      "q2: приехала как то теща в гости к своему другу в гости к своему другу в\n",
      "q3: говорит чебурашка гене а даваи те я вам не стыдно вы сорок лет водил моисей евреев\n",
      "q4: что общего между евреем и неглупым крепкости бодрит шагов поговорит прижатой амеиканская паи полисмена дуреют рно\n"
     ]
    }
   ],
   "source": [
    "for i, test in enumerate(test_data):\n",
    "    ans = stat_lm.generate(test, generation_config)\n",
    "    print(f'q{i}: {ans}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T19:12:19.264320Z",
     "iopub.status.busy": "2024-03-19T19:12:19.263874Z",
     "iopub.status.idle": "2024-03-19T19:12:19.271142Z",
     "shell.execute_reply": "2024-03-19T19:12:19.269571Z",
     "shell.execute_reply.started": "2024-03-19T19:12:19.264290Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(temperature = 2, max_tokens = 16,\n",
    "                                     sample_top_p = 0.012, decoding_strategy = 'top-p',\n",
    "                                     remove_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T19:12:20.746587Z",
     "iopub.status.busy": "2024-03-19T19:12:20.746154Z",
     "iopub.status.idle": "2024-03-19T19:12:50.604024Z",
     "shell.execute_reply": "2024-03-19T19:12:50.602939Z",
     "shell.execute_reply.started": "2024-03-19T19:12:20.746557Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q0: встретились как то русский и американец попали в ад а черти то бедные в рекрутеры\n",
      "q1: сидит штирлиц в засаде на проспекте гагарина такая намордника накидаться неимущим групповухой исчезнете ваааах перебрала кормильцу\n",
      "q2: приехала как то теща в гости к своему другу в гости к своему другу в\n",
      "q3: говорит чебурашка гене а даваи те я вам не стыдно вы сорок лет водил моисей евреев\n",
      "q4: что общего между евреем и неглупым человеком а этот лексус уже был помятый и кот это\n"
     ]
    }
   ],
   "source": [
    "for i, test in enumerate(test_data):\n",
    "    ans = stat_lm.generate(test, generation_config)\n",
    "    print(f'q{i}: {ans}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T19:25:37.595953Z",
     "iopub.status.busy": "2024-03-19T19:25:37.595540Z",
     "iopub.status.idle": "2024-03-19T19:25:37.601673Z",
     "shell.execute_reply": "2024-03-19T19:25:37.600217Z",
     "shell.execute_reply.started": "2024-03-19T19:25:37.595922Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(temperature = 2.1, max_tokens = 16,\n",
    "                                     sample_top_p = 0.0129, decoding_strategy = 'top-p',\n",
    "                                     remove_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T19:25:38.634943Z",
     "iopub.status.busy": "2024-03-19T19:25:38.634555Z",
     "iopub.status.idle": "2024-03-19T19:26:06.926060Z",
     "shell.execute_reply": "2024-03-19T19:26:06.924311Z",
     "shell.execute_reply.started": "2024-03-19T19:25:38.634916Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q0: встретились как то русский и американец попали в ад а черти то бедные в холодильнике\n",
      "q1: сидит штирлиц в засаде на углу улицы стоит нищий сапожков скромничаи расшарил красавцев гейшей доме плоскостопсть\n",
      "q2: приехала как то теща в гости к своему другу в гости к своему другу в\n",
      "q3: говорит чебурашка гене гена гена шапокляк родила что листков стынут терма бриалиантами разморозив потустронних клейковина можется\n",
      "q4: что общего между евреем и неглупым человеком абмоба зарубим хвастайся поклажей таблетку комдессю бухаешь онколога петросянизма\n"
     ]
    }
   ],
   "source": [
    "for i, test in enumerate(test_data):\n",
    "    ans = stat_lm.generate(test, generation_config)\n",
    "    print(f'q{i}: {ans}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T19:26:44.834180Z",
     "iopub.status.busy": "2024-03-19T19:26:44.833674Z",
     "iopub.status.idle": "2024-03-19T19:26:50.238574Z",
     "shell.execute_reply": "2024-03-19T19:26:50.237343Z",
     "shell.execute_reply.started": "2024-03-19T19:26:44.834145Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save('tokenizer.pkl')\n",
    "stat_lm.save_stat('stat_lm.pkl')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1697417,
     "sourceId": 2780478,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4589730,
     "sourceId": 7888445,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
